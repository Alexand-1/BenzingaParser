# Парсер Benzinga

Парсер Benzinga - это сценарий на Python для парсинга новостей с веб-сайта Benzinga и сохранения данных в базе данных MongoDB.
Скрипт использует библиотеки requests и BeautifulSoup для парсинга, а также pymongo для взаимодействия с MongoDB и logging для логирования.
Периодическое обновление данных реализовано с использованием библиотеки schedule.

Принцип работы:

Сам скрипт разделен на 2 части:
1 выборка всех отдельных новостей на сайте и запись их url
2 для каждой отдельной новости записывает в бд:
  ее url
  название статьи
  текст статьи
  время и дата публикации


более подробно с тем как записываются данные можно посмотреть в файле parser.log


При правильной настройке зависимостей и запуске скрипта в первый раз все новости, которые были обнаружены парсером будут добавлены в бд, после идет неприрывнй цикл обхода.
При каждом обходе будут находится последние новости и если какая то новость не занесена в бд, то скрипт записывает ее, если же скрипт видит что по ссылке такая новость уже записана, то просто пропускает ее


скрипт обновляется каждые 40 сек.(Вы можете установить свои значения для обновления)

## Инструкции по установке и использованию

1. Установка зависимостей:
   Убедитесь, что у вас установлены Python, pip и MongoDB(убедитесь что у вас скачана и установлена, в противном случае нужно будет скачать и настроить) .

   ```bash
   pip install requests
   pip install beautifulsoup4
   pip install pymongo
   pip install schedule
   pip install logging

Клонирование репозитория:

git clone https://github.com/ваш-логин/BenzingaParser.git
cd BenzingaParser


